# GPT Builder V2 â€“ IntegraÃ§Ã£o SimbÃ³lica com Chat

## ğŸ“‹ VisÃ£o Geral

Esta implementaÃ§Ã£o integra a atenÃ§Ã£o semÃ¢ntica com a gramÃ¡tica clÃ­nica da NÃ´a Esperanza, criando um sistema de processamento de mensagens baseado em:

- **Vector Search**: Busca semÃ¢ntica de documentos relevantes
- **GramÃ¡tica NÃ´a**: Enriquecimento com metodologia da Arte da Entrevista ClÃ­nica
- **GPT-4o**: GeraÃ§Ã£o de respostas contextualizadas e empÃ¡ticas

## ğŸ”§ Componentes Implementados

### 1. `semanticAttentionService.ts`

**FunÃ§Ã£o: `processUserMessage(message: string, userContext: string)`**

FunÃ§Ã£o principal que integra todo o fluxo:
- Busca vetorial de documentos relevantes
- Enriquecimento com gramÃ¡tica clÃ­nica
- GeraÃ§Ã£o de resposta via OpenAI

**FunÃ§Ã£o: `buildUserSymbolicContext(userId?: string, conversationHistory?: any[])`**

ConstrÃ³i o contexto simbÃ³lico do usuÃ¡rio baseado em:
- ID do usuÃ¡rio
- HistÃ³rico de conversaÃ§Ã£o

### 2. `gptBuilderService.ts`

**FunÃ§Ã£o: `enrichWithNoaGrammar(message: string, docs: any[], context: string)`**

Enriquece a mensagem com:
- InstruÃ§Ãµes base da NÃ´a Esperanza
- Metodologia da Arte da Entrevista ClÃ­nica
- Documentos relevantes do vector search
- Contexto simbÃ³lico do usuÃ¡rio

MÃ©todo de resposta estruturado:
1. Nomear o que foi trazido (escuta ativa)
2. Relacionar com a base documental
3. Responder com empatia e linguagem acessÃ­vel

### 3. `openaiService.ts`

**FunÃ§Ã£o: `sendToOpenAI(fullPrompt: string)`**

Envia o prompt completo para GPT-4o com:
- Modelo: `gpt-4o`
- Sistema: Identidade da NÃ´a Esperanza
- Temperature: 0.7 (equilÃ­brio entre criatividade e precisÃ£o)

### 4. `supabase/embeddingClient.ts`

**FunÃ§Ã£o: `getVectorMatch(query: string)`**

Busca vetorial de documentos relevantes via API:
- Endpoint: `/api/embedding/search`
- Retorna documentos semanticamente similares Ã  query

## ğŸ’¡ Exemplo de Uso

### IntegraÃ§Ã£o BÃ¡sica no Chat

```typescript
import { processUserMessage, buildUserSymbolicContext } from '../services/semanticAttentionService'

const ChatWindow = () => {
  const [messages, setMessages] = useState([])
  const [input, setInput] = useState('')

  const handleSendMessage = async () => {
    const userMessage = input
    
    // Adiciona mensagem do usuÃ¡rio
    setMessages([...messages, { role: "user", content: userMessage }])
    
    // ConstrÃ³i contexto simbÃ³lico
    const userContext = buildUserSymbolicContext('user-123', messages)
    
    // Processa mensagem com atenÃ§Ã£o semÃ¢ntica
    const reply = await processUserMessage(userMessage, userContext)
    
    // Adiciona resposta da NÃ´a
    setMessages(prev => [...prev, { role: "assistant", content: reply }])
    
    setInput("")
  }

  return (
    // ... JSX do componente
  )
}
```

### IntegraÃ§Ã£o AvanÃ§ada com Hook Existente

```typescript
import { processUserMessage, buildUserSymbolicContext } from '../services/semanticAttentionService'

export const useNoaChat = ({ userMemory, addNotification }) => {
  const [messages, setMessages] = useState([])
  
  const getNoaResponse = async (userMessage: string) => {
    try {
      // Construir contexto do usuÃ¡rio
      const userContext = buildUserSymbolicContext(
        userMemory.userId, 
        messages
      )
      
      // Processar com atenÃ§Ã£o semÃ¢ntica e gramÃ¡tica NÃ´a
      const response = await processUserMessage(userMessage, userContext)
      
      // Adicionar resposta Ã s mensagens
      setMessages(prev => [...prev, {
        id: crypto.randomUUID(),
        message: response,
        sender: 'noa',
        timestamp: new Date()
      }])
      
    } catch (error) {
      console.error('Erro ao processar mensagem:', error)
    }
  }
  
  return { getNoaResponse, messages }
}
```

## ğŸ¯ BenefÃ­cios da IntegraÃ§Ã£o

1. **Escuta Ativa**: Cada resposta nomeia o que foi trazido pelo usuÃ¡rio
2. **Base Documental**: Respostas fundamentadas em documentos relevantes
3. **Empatia ClÃ­nica**: Linguagem acessÃ­vel e acolhedora
4. **Contexto SimbÃ³lico**: MemÃ³ria do histÃ³rico do usuÃ¡rio
5. **PrecisÃ£o SemÃ¢ntica**: Busca vetorial de conteÃºdos relevantes

## ğŸ”„ Fluxo de Processamento

```
Mensagem do UsuÃ¡rio
       â†“
buildUserSymbolicContext() â†’ ConstrÃ³i contexto
       â†“
processUserMessage()
       â”œâ†’ getVectorMatch() â†’ Busca documentos relevantes
       â”œâ†’ enrichWithNoaGrammar() â†’ Enriquece com gramÃ¡tica clÃ­nica
       â””â†’ sendToOpenAI() â†’ Gera resposta via GPT-4o
       â†“
Resposta da NÃ´a Esperanza
```

## ğŸ“ Notas TÃ©cnicas

- **Imports Lazy**: Uso de imports dinÃ¢micos para evitar dependÃªncias circulares
- **Tratamento de Erros**: Implementar try-catch em cada integraÃ§Ã£o
- **API Endpoint**: O endpoint `/api/embedding/search` precisa estar configurado no backend
- **Environment Variables**: `VITE_OPENAI_API_KEY` deve estar configurada

## ğŸš€ PrÃ³ximos Passos

1. Implementar endpoint `/api/embedding/search` no backend
2. Configurar embeddings dos documentos mestres
3. Adicionar testes unitÃ¡rios para cada funÃ§Ã£o
4. Integrar com componentes de UI existentes
5. Adicionar mÃ©tricas de qualidade das respostas
